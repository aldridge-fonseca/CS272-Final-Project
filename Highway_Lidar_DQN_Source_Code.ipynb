{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a96cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "SAVE_DIR = \"/content/drive/MyDrive/highway_results/lidar_dqn\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3ed90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install highway-env stable-baselines3 gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "\n",
    "import highway_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1683c9f",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"LidarObservation\",\n",
    "        \"cells\": 64,\n",
    "        \"maximum_range\": 60,\n",
    "        \"normalize\": True\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "    },\n",
    "    \"lanes_count\": 4,\n",
    "    \"duration\": 40,\n",
    "    \"collision_reward\": -1.0,\n",
    "    \"reward_speed_range\": [20, 30],\n",
    "    \"simulation_frequency\": 15,\n",
    "    \"policy_frequency\": 5,\n",
    "}\n",
    "\n",
    "def create_env():\n",
    "    env = gym.make(\"highway-fast-v0\", render_mode=None, config=env_config)\n",
    "    return env\n",
    "\n",
    "test_env = create_env()\n",
    "obs, _ = test_env.reset()\n",
    "print(f\"Observation shape: {obs.shape}\")\n",
    "print(f\"Action space: {test_env.action_space}\")\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a7e70",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, save_path, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_rewards = []\n",
    "        self.current_rewards = 0\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        self.current_rewards += self.locals['rewards'][0]\n",
    "        if self.locals['dones'][0]:\n",
    "            self.episode_rewards.append(self.current_rewards)\n",
    "            self.current_rewards = 0\n",
    "            if len(self.episode_rewards) % 100 == 0:\n",
    "                np.save(f\"{self.save_path}/episode_rewards.npy\", self.episode_rewards)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37905192",
   "metadata": {},
   "source": [
    "## DQN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e20974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DummyVecEnv([create_env])\n",
    "\n",
    "policy_kwargs = dict(net_arch=[256, 256])\n",
    "\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    learning_rate=5e-4,\n",
    "    buffer_size=15000,\n",
    "    learning_starts=200,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    train_freq=4,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=1000,\n",
    "    exploration_fraction=0.3,\n",
    "    exploration_final_eps=0.05,\n",
    "    verbose=1,\n",
    "    tensorboard_log=f\"{SAVE_DIR}/tensorboard/\",\n",
    "    device=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ebbb2e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ff12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_callback = RewardLoggerCallback(SAVE_DIR)\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=25000,\n",
    "    save_path=SAVE_DIR,\n",
    "    name_prefix=\"highway_lidar_dqn\"\n",
    ")\n",
    "\n",
    "TOTAL_TIMESTEPS = 200000\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=TOTAL_TIMESTEPS,\n",
    "    callback=[reward_callback, checkpoint_callback],\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "model.save(f\"{SAVE_DIR}/highway_lidar_final_1\")\n",
    "np.save(f\"{SAVE_DIR}/episode_rewards.npy\", reward_callback.episode_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d915e",
   "metadata": {},
   "source": [
    "## Learning Curve (ID 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array(reward_callback.episode_rewards)\n",
    "\n",
    "window = 50\n",
    "rolling_mean = np.convolve(rewards, np.ones(window)/window, mode='valid')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(rewards, alpha=0.3, color='blue', label='Episode Reward')\n",
    "plt.plot(range(window-1, len(rewards)), rolling_mean, color='blue', linewidth=2, label=f'Rolling Mean ({window} ep)')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Mean Episodic Reward (Return)')\n",
    "plt.title('Highway LiDAR DQN - Learning Curve (ID 1)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{SAVE_DIR}/highway_lidar_learning_curve_1.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857354c",
   "metadata": {},
   "source": [
    "## Performance Test (ID 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = DQN.load(f\"{SAVE_DIR}/highway_lidar_final_1\")\n",
    "\n",
    "eval_env = create_env()\n",
    "\n",
    "n_episodes = 500\n",
    "test_rewards = []\n",
    "\n",
    "for ep in range(n_episodes):\n",
    "    obs, _ = eval_env.reset()\n",
    "    done = truncated = False\n",
    "    episode_reward = 0\n",
    "    \n",
    "    while not (done or truncated):\n",
    "        action, _ = eval_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, _ = eval_env.step(action)\n",
    "        episode_reward += reward\n",
    "    \n",
    "    test_rewards.append(episode_reward)\n",
    "\n",
    "eval_env.close()\n",
    "\n",
    "np.save(f\"{SAVE_DIR}/test_rewards_500ep.npy\", test_rewards)\n",
    "print(f\"Mean: {np.mean(test_rewards):.2f}, Std: {np.std(test_rewards):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "parts = plt.violinplot([test_rewards], positions=[1], showmeans=True, showmedians=False)\n",
    "\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('steelblue')\n",
    "    pc.set_alpha(0.7)\n",
    "\n",
    "quartile1 = np.percentile(test_rewards, 25)\n",
    "median = np.percentile(test_rewards, 50)\n",
    "quartile3 = np.percentile(test_rewards, 75)\n",
    "\n",
    "plt.hlines([quartile1, median, quartile3], 0.8, 1.2, colors='blue', linewidth=1.5)\n",
    "\n",
    "plt.ylabel('Episodic Reward (Return)')\n",
    "plt.title('Performance Test - 500 Episodes (ID 2)')\n",
    "plt.xticks([1], ['Highway LiDAR\\nDQN Agent'])\n",
    "\n",
    "mean_reward = np.mean(test_rewards)\n",
    "std_reward = np.std(test_rewards)\n",
    "plt.text(1.3, mean_reward, f'Mean: {mean_reward:.2f}\\nStd: {std_reward:.2f}', \n",
    "         verticalalignment='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{SAVE_DIR}/highway_lidar_performance_2.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f75b8",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a745211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for f in glob.glob(f\"{SAVE_DIR}/*\"):\n",
    "    print(f\"  {os.path.basename(f)}\")\n",
    "\n",
    "shutil.make_archive('/content/highway_lidar_final', 'zip', SAVE_DIR)\n",
    "files.download('/content/highway_lidar_final.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
